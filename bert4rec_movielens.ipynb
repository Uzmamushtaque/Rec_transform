{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 77759,
          "sourceType": "datasetVersion",
          "datasetId": 339
        },
        {
          "sourceId": 2622,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 1899
        }
      ],
      "dockerImageVersionId": 30528,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzmamushtaque/Rec_transform/blob/main/bert4rec_movielens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# from box import Box\n",
        "\n",
        "import warnings"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:27:10.777447Z",
          "iopub.execute_input": "2024-04-29T20:27:10.777816Z",
          "iopub.status.idle": "2024-04-29T20:27:14.257223Z",
          "shell.execute_reply.started": "2024-04-29T20:27:10.777762Z",
          "shell.execute_reply": "2024-04-29T20:27:14.256248Z"
        },
        "trusted": true,
        "id": "7b_coTY7LQsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'data_path' : '/content/ratings.csv',\n",
        "    'max_len' : 50,\n",
        "    'hidden_units' : 256, # Embedding size\n",
        "    'num_heads' : 2, # Multi-head layer\n",
        "    'num_layers': 2, # block (encoder layer)\n",
        "    'dropout_rate' : 0.1, # dropout\n",
        "    'lr' : 0.001,\n",
        "    'batch_size' : 128,\n",
        "    'num_epochs' : 10,\n",
        "    'num_workers' : 2,\n",
        "    'mask_prob' : 0.15, # for cloze task\n",
        "}\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:27:34.720273Z",
          "iopub.execute_input": "2024-04-29T20:27:34.720851Z",
          "iopub.status.idle": "2024-04-29T20:27:34.756216Z",
          "shell.execute_reply.started": "2024-04-29T20:27:34.720820Z",
          "shell.execute_reply": "2024-04-29T20:27:34.754967Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QcjYGVDLQsR",
        "outputId": "b57fe7a0-c23f-410f-931b-a9bde59c46b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "mJ32ZUzuLQsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MakeSequenceDataSet():\n",
        "    \"\"\"\n",
        "    SequenceData\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        #self.df = pd.read_csv(os.path.join(config['data_path'], 'rating.csv'))\n",
        "        self.df = pd.read_csv(config['data_path'])\n",
        "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('movieId')\n",
        "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('userId')\n",
        "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
        "\n",
        "        self.df['item_idx'] = self.df['movieId'].apply(lambda x : self.item_encoder[x] + 1)\n",
        "        self.df['user_idx'] = self.df['userId'].apply(lambda x : self.user_encoder[x])\n",
        "        self.df = self.df.sort_values(['user_idx', 'timestamp'])\n",
        "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
        "\n",
        "    def generate_encoder_decoder(self, col : str) -> dict:\n",
        "        \"\"\"\n",
        "        encoder, decoder\n",
        "\n",
        "        Args:\n",
        "            col (str):  columns\n",
        "        Returns:\n",
        "            dict: user encoder, decoder\n",
        "        \"\"\"\n",
        "\n",
        "        encoder = {}\n",
        "        decoder = {}\n",
        "        ids = self.df[col].unique()\n",
        "\n",
        "        for idx, _id in enumerate(ids):\n",
        "            encoder[_id] = idx\n",
        "            decoder[idx] = _id\n",
        "\n",
        "        return encoder, decoder\n",
        "\n",
        "    def generate_sequence_data(self) -> dict:\n",
        "        \"\"\"\n",
        "        sequence_data\n",
        "\n",
        "        Returns:\n",
        "            dict: train user sequence / valid user sequence\n",
        "        \"\"\"\n",
        "        users = defaultdict(list)\n",
        "        user_train = {}\n",
        "        user_valid = {}\n",
        "        group_df = self.df.groupby('user_idx')\n",
        "        for user, item in group_df:\n",
        "            users[user].extend(item['item_idx'].tolist())\n",
        "\n",
        "        for user in users:\n",
        "            user_train[user] = users[user][:-1]\n",
        "            user_valid[user] = [users[user][-1]]\n",
        "\n",
        "        return user_train, user_valid\n",
        "\n",
        "    def get_train_valid_data(self):\n",
        "        return self.user_train, self.user_valid"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-29T20:27:55.111443Z",
          "iopub.execute_input": "2024-04-29T20:27:55.112258Z",
          "iopub.status.idle": "2024-04-29T20:27:55.124517Z",
          "shell.execute_reply.started": "2024-04-29T20:27:55.112225Z",
          "shell.execute_reply": "2024-04-29T20:27:55.123554Z"
        },
        "trusted": true,
        "id": "ZrAm0q6XLQsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = MakeSequenceDataSet(config)"
      ],
      "metadata": {
        "id": "TJo_DY-YunRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTRecDataSet(Dataset):\n",
        "    def __init__(self, user_train, max_len, num_user, num_item, mask_prob):\n",
        "        self.user_train = user_train\n",
        "        self.max_len = max_len\n",
        "        self.num_user = num_user\n",
        "        self.num_item = num_item\n",
        "        self.mask_prob = mask_prob\n",
        "        self._all_items = set([i for i in range(1, self.num_item + 1)])\n",
        "\n",
        "    def __len__(self):\n",
        "        #  user sequence\n",
        "        return self.num_user\n",
        "\n",
        "    def __getitem__(self, user):\n",
        "\n",
        "        user_seq = self.user_train[user]\n",
        "        tokens = []\n",
        "        labels = []\n",
        "        for s in user_seq[-self.max_len:]:\n",
        "            prob = np.random.random()\n",
        "            if prob < self.mask_prob:\n",
        "                prob /= self.mask_prob\n",
        "                if prob < 0.8:\n",
        "                    # masking\n",
        "                    tokens.append(self.num_item + 1)  # mask_index: num_item + 1, 0: pad, 1~num_item: item index\n",
        "                elif prob < 0.9:\n",
        "                    # noise\n",
        "                    tokens.extend(self.random_neg_sampling(rated_item = user_seq, num_item_sample = 1))  # item random sampling\n",
        "                else:\n",
        "                    tokens.append(s)\n",
        "                labels.append(s)\n",
        "            else:\n",
        "                tokens.append(s)\n",
        "                labels.append(0)\n",
        "\n",
        "        mask_len = self.max_len - len(tokens)\n",
        "        tokens = [0] * mask_len + tokens\n",
        "        labels = [0] * mask_len + labels\n",
        "\n",
        "        return torch.LongTensor(tokens), torch.LongTensor(labels)\n",
        "\n",
        "    def random_neg_sampling(self, rated_item : list, num_item_sample : int):\n",
        "        nge_samples = random.sample(list(self._all_items - set(rated_item)), num_item_sample)\n",
        "        return nge_samples"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:29:02.080058Z",
          "iopub.execute_input": "2024-04-29T20:29:02.080747Z",
          "iopub.status.idle": "2024-04-29T20:29:02.093170Z",
          "shell.execute_reply.started": "2024-04-29T20:29:02.080714Z",
          "shell.execute_reply": "2024-04-29T20:29:02.091009Z"
        },
        "trusted": true,
        "id": "4zSe5QnHLQsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "bn9_7C4yLQsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, max_len, d_model):\n",
        "        super().__init__()\n",
        "\n",
        "        # Compute the positional encodings once in log space.\n",
        "        self.pe = nn.Embedding(max_len, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        return self.pe.weight.unsqueeze(0).repeat(batch_size, 1, 1)\n",
        "\n",
        "class TokenEmbedding(nn.Embedding):\n",
        "    def __init__(self, vocab_size, embed_size=512):\n",
        "        super().__init__(vocab_size, embed_size, padding_idx=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:29:58.703889Z",
          "iopub.execute_input": "2024-04-29T20:29:58.704248Z",
          "iopub.status.idle": "2024-04-29T20:29:58.711199Z",
          "shell.execute_reply.started": "2024-04-29T20:29:58.704218Z",
          "shell.execute_reply": "2024-04-29T20:29:58.710149Z"
        },
        "trusted": true,
        "id": "uvlYNER-LQsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    BERT Embedding which is consisted with under features\n",
        "        1. TokenEmbedding : normal embedding matrix\n",
        "        2. PositionalEmbedding : adding positional information using sin, cos\n",
        "        2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)\n",
        "\n",
        "        sum of all these features are output of BERTEmbedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, embed_size, max_len, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param vocab_size: total vocab size\n",
        "        :param embed_size: embedding size of token embedding\n",
        "        :param dropout: dropout rate\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.token = TokenEmbedding(vocab_size=vocab_size, embed_size=embed_size)\n",
        "        self.position = PositionalEmbedding(max_len=max_len, d_model=embed_size)\n",
        "        # self.segment = SegmentEmbedding(embed_size=self.token.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        x = self.token(sequence) + self.position(sequence)\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:30:21.075593Z",
          "iopub.execute_input": "2024-04-29T20:30:21.075997Z",
          "iopub.status.idle": "2024-04-29T20:30:21.083024Z",
          "shell.execute_reply.started": "2024-04-29T20:30:21.075967Z",
          "shell.execute_reply": "2024-04-29T20:30:21.082049Z"
        },
        "trusted": true,
        "id": "ZL_SJyabLQsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = BERTEmbedding(26744, 768, 150, dropout=0.1)"
      ],
      "metadata": {
        "id": "r7aC7ooO1glU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.position.pe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHkV0drr4Nip",
        "outputId": "6784f554-fa39-45ce-99f2-fb3486e8185e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(150, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#b.forward(torch.tensor(s.user_train[0]))"
      ],
      "metadata": {
        "id": "AnTAZW4r4TFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    Compute 'Scaled Dot Product Attention\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, query, key, value, mask=None, dropout=None):\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
        "                 / math.sqrt(query.size(-1))\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        p_attn = F.softmax(scores, dim=-1)\n",
        "\n",
        "        if dropout is not None:\n",
        "            p_attn = dropout(p_attn)\n",
        "\n",
        "        return torch.matmul(p_attn, value), p_attn"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:30:27.829191Z",
          "iopub.execute_input": "2024-04-29T20:30:27.829931Z",
          "iopub.status.idle": "2024-04-29T20:30:27.836482Z",
          "shell.execute_reply.started": "2024-04-29T20:30:27.829899Z",
          "shell.execute_reply": "2024-04-29T20:30:27.835491Z"
        },
        "trusted": true,
        "id": "CJjF-bENLQsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Take in model size and number of heads.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % h == 0\n",
        "\n",
        "        # We assume d_v always equals d_k\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "\n",
        "        self.linear_layers = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(3)])\n",
        "        self.output_linear = nn.Linear(d_model, d_model)\n",
        "        self.attention = Attention()\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
        "        query, key, value = [l(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
        "                             for l, x in zip(self.linear_layers, (query, key, value))]\n",
        "\n",
        "        # 2) Apply attention on all the projected vectors in batch.\n",
        "        x, attn = self.attention(query, key, value, mask=mask, dropout=self.dropout)\n",
        "\n",
        "        # 3) \"Concat\" using a view and apply a final linear.\n",
        "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n",
        "\n",
        "        return self.output_linear(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:30:41.412505Z",
          "iopub.execute_input": "2024-04-29T20:30:41.413261Z",
          "iopub.status.idle": "2024-04-29T20:30:41.422570Z",
          "shell.execute_reply.started": "2024-04-29T20:30:41.413229Z",
          "shell.execute_reply": "2024-04-29T20:30:41.421517Z"
        },
        "trusted": true,
        "id": "cywn30OFLQsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "    \"\"\"\n",
        "    Paper Section 3.4, last paragraph notice that BERT used the GELU instead of RELU\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:31:03.126964Z",
          "iopub.execute_input": "2024-04-29T20:31:03.127709Z",
          "iopub.status.idle": "2024-04-29T20:31:03.132938Z",
          "shell.execute_reply.started": "2024-04-29T20:31:03.127680Z",
          "shell.execute_reply": "2024-04-29T20:31:03.131951Z"
        },
        "trusted": true,
        "id": "xwdr57lyLQse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"Implements FFN equation.\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(self.activation(self.w_1(x))))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:31:09.951669Z",
          "iopub.execute_input": "2024-04-29T20:31:09.952495Z",
          "iopub.status.idle": "2024-04-29T20:31:09.959141Z",
          "shell.execute_reply.started": "2024-04-29T20:31:09.952453Z",
          "shell.execute_reply": "2024-04-29T20:31:09.958245Z"
        },
        "trusted": true,
        "id": "9nxudXUtLQsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    \"Construct a layernorm module (See citation for details).\"\n",
        "\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:31:18.426155Z",
          "iopub.execute_input": "2024-04-29T20:31:18.426477Z",
          "iopub.status.idle": "2024-04-29T20:31:18.433239Z",
          "shell.execute_reply.started": "2024-04-29T20:31:18.426452Z",
          "shell.execute_reply": "2024-04-29T20:31:18.432208Z"
        },
        "trusted": true,
        "id": "6-ihhOtJLQsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "    \"\"\"\n",
        "    A residual connection followed by a layer norm.\n",
        "    Note for code simplicity the norm is first as opposed to last.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        \"Apply residual connection to any sublayer with the same size.\"\n",
        "        return x + self.dropout(sublayer(self.norm(x)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:31:29.548428Z",
          "iopub.execute_input": "2024-04-29T20:31:29.549155Z",
          "iopub.status.idle": "2024-04-29T20:31:29.555373Z",
          "shell.execute_reply.started": "2024-04-29T20:31:29.549122Z",
          "shell.execute_reply": "2024-04-29T20:31:29.554023Z"
        },
        "trusted": true,
        "id": "67BdTinlLQsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Bidirectional Encoder = Transformer (self-attention)\n",
        "    Transformer = MultiHead_Attention + Feed_Forward with sublayer connection\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden, attn_heads, feed_forward_hidden, dropout):\n",
        "        \"\"\"\n",
        "        :param hidden: hidden size of transformer\n",
        "        :param attn_heads: head sizes of multi-head attention\n",
        "        :param feed_forward_hidden: feed_forward_hidden, usually 4*hidden_size\n",
        "        :param dropout: dropout rate\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadedAttention(h=attn_heads, d_model=hidden, dropout=dropout)\n",
        "        self.feed_forward = PositionwiseFeedForward(d_model=hidden, d_ff=feed_forward_hidden, dropout=dropout)\n",
        "        self.input_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
        "        self.output_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.input_sublayer(x, lambda _x: self.attention.forward(_x, _x, _x, mask=mask))\n",
        "        x = self.output_sublayer(x, self.feed_forward)\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:31:37.945465Z",
          "iopub.execute_input": "2024-04-29T20:31:37.946310Z",
          "iopub.status.idle": "2024-04-29T20:31:37.954254Z",
          "shell.execute_reply.started": "2024-04-29T20:31:37.946276Z",
          "shell.execute_reply": "2024-04-29T20:31:37.953176Z"
        },
        "trusted": true,
        "id": "c2LSC5iqLQsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from utils import fix_random_seed_as\n",
        "\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self, bert_max_len, num_items, bert_num_blocks, bert_num_heads,\n",
        "                 bert_hidden_units, bert_dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        # fix_random_seed_as(args.model_init_seed)\n",
        "        # self.init_weights()\n",
        "\n",
        "        max_len = bert_max_len\n",
        "        num_items = num_items\n",
        "        n_layers = bert_num_blocks\n",
        "        heads = bert_num_heads\n",
        "        vocab_size = num_items + 2\n",
        "        hidden = bert_hidden_units\n",
        "        self.hidden = hidden\n",
        "        dropout = bert_dropout\n",
        "\n",
        "        # embedding for BERT, sum of positional, segment, token embeddings\n",
        "        self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=self.hidden, max_len=max_len, dropout=dropout)\n",
        "\n",
        "        # multi-layers transformer blocks, deep network\n",
        "        self.transformer_blocks = nn.ModuleList(\n",
        "            [TransformerBlock(hidden, heads, hidden * 4, dropout) for _ in range(n_layers)])\n",
        "        self.out = nn.Linear(hidden, num_items + 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mask = (x > 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
        "\n",
        "        # embedding the indexed sequence to sequence of vectors\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # running over multiple transformer blocks\n",
        "        for transformer in self.transformer_blocks:\n",
        "            x = transformer.forward(x, mask)\n",
        "\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "    def init_weights(self):\n",
        "        pass\n",
        "\n",
        "net = BERT(10, 10, 6, 8, 8, 0.4)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:32:03.184260Z",
          "iopub.execute_input": "2024-04-29T20:32:03.185092Z",
          "iopub.status.idle": "2024-04-29T20:32:03.243347Z",
          "shell.execute_reply.started": "2024-04-29T20:32:03.185059Z",
          "shell.execute_reply": "2024-04-29T20:32:03.242364Z"
        },
        "trusted": true,
        "id": "axvVRnm6LQsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "uwMbyBSyLQsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, data_loader):\n",
        "    model.train()\n",
        "    loss_val = 0\n",
        "    for seq, labels in tqdm(data_loader):\n",
        "        seq, labels = seq.to(device), labels.to(device)\n",
        "        logits = model(seq) # (bs, t, vocab)\n",
        "        logits = logits.view(-1, logits.size(-1)) # (bs * t, vocab)\n",
        "        labels = labels.view(-1) # (bs * t)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss_val += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_val /= len(data_loader)\n",
        "\n",
        "    return loss_val\n",
        "\n",
        "def evaluate(model, user_train, user_valid, max_len, data_loader, bert4rec_dataset, make_sequence_dataset):\n",
        "    model.eval()\n",
        "\n",
        "    NDCG = 0.0 # NDCG@10\n",
        "    HIT = 0.0 # HIT@10\n",
        "\n",
        "    num_item_sample = 100\n",
        "\n",
        "    users = [user for user in range(make_sequence_dataset.num_user)]\n",
        "\n",
        "    for user in tqdm(users):\n",
        "        seq = (user_train[user] + [make_sequence_dataset.num_item + 1])[-max_len:] # mask last token\n",
        "        padding_len = max_len - len(seq)\n",
        "        seq = [0] * padding_len + seq\n",
        "        rated = user_train[user] + user_valid[user]\n",
        "        items = user_valid[user] + bert4rec_dataset.random_neg_sampling(rated_item = rated, num_item_sample = num_item_sample)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            seq = torch.LongTensor([seq]).to(device)\n",
        "            predictions = -model(seq)\n",
        "#             print(predictions.shape)\n",
        "            predictions = predictions[0][-1][items] # sampling\n",
        "#             print(predictions.shape)\n",
        "            rank = predictions.argsort().argsort()[0].item() # label\n",
        "\n",
        "        if rank < 10: #Top10\n",
        "            NDCG += 1 / np.log2(rank + 2)\n",
        "            HIT += 1\n",
        "\n",
        "    NDCG /= len(users)\n",
        "    HIT /= len(users)\n",
        "\n",
        "    return NDCG, HIT"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:32:35.326138Z",
          "iopub.execute_input": "2024-04-29T20:32:35.326500Z",
          "iopub.status.idle": "2024-04-29T20:32:35.338719Z",
          "shell.execute_reply.started": "2024-04-29T20:32:35.326470Z",
          "shell.execute_reply": "2024-04-29T20:32:35.337762Z"
        },
        "trusted": true,
        "id": "zQ91uwYqLQsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_sequence_dataset = MakeSequenceDataSet(config)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:32:43.091263Z",
          "iopub.execute_input": "2024-04-29T20:32:43.091868Z",
          "iopub.status.idle": "2024-04-29T20:35:01.627523Z",
          "shell.execute_reply.started": "2024-04-29T20:32:43.091837Z",
          "shell.execute_reply": "2024-04-29T20:35:01.626696Z"
        },
        "trusted": true,
        "id": "gufnBvlzLQsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_train, user_valid = make_sequence_dataset.get_train_valid_data()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:35:10.975828Z",
          "iopub.execute_input": "2024-04-29T20:35:10.976618Z",
          "iopub.status.idle": "2024-04-29T20:35:10.980731Z",
          "shell.execute_reply.started": "2024-04-29T20:35:10.976588Z",
          "shell.execute_reply": "2024-04-29T20:35:10.979726Z"
        },
        "trusted": true,
        "id": "wrX99sdrLQsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert4rec_dataset = BERTRecDataSet(\n",
        "    user_train = user_train,\n",
        "    max_len = config['max_len'],\n",
        "    num_user = make_sequence_dataset.num_user,\n",
        "    num_item = make_sequence_dataset.num_item,\n",
        "    mask_prob = config['mask_prob'],\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:35:27.250329Z",
          "iopub.execute_input": "2024-04-29T20:35:27.251190Z",
          "iopub.status.idle": "2024-04-29T20:35:27.257968Z",
          "shell.execute_reply.started": "2024-04-29T20:35:27.251158Z",
          "shell.execute_reply": "2024-04-29T20:35:27.256987Z"
        },
        "trusted": true,
        "id": "AFkK_Uk4LQsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(\n",
        "    bert4rec_dataset,\n",
        "    batch_size = config['batch_size'],\n",
        "    shuffle = True,\n",
        "    pin_memory = True,\n",
        "    num_workers = config['num_workers'],\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:35:44.373285Z",
          "iopub.execute_input": "2024-04-29T20:35:44.374110Z",
          "iopub.status.idle": "2024-04-29T20:35:44.378627Z",
          "shell.execute_reply.started": "2024-04-29T20:35:44.374076Z",
          "shell.execute_reply": "2024-04-29T20:35:44.377629Z"
        },
        "trusted": true,
        "id": "KAq1AxkTLQsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = BERT(\n",
        "    num_items = 26744,\n",
        "    bert_hidden_units = config['hidden_units'],\n",
        "    bert_num_heads = config['num_heads'],\n",
        "    bert_num_blocks = config['num_layers'],\n",
        "    bert_max_len = config['max_len'],\n",
        "    bert_dropout = config['dropout_rate'],\n",
        "    ).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0) # label (padding)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:35:58.261245Z",
          "iopub.execute_input": "2024-04-29T20:35:58.261924Z",
          "iopub.status.idle": "2024-04-29T20:35:58.562808Z",
          "shell.execute_reply.started": "2024-04-29T20:35:58.261892Z",
          "shell.execute_reply": "2024-04-29T20:35:58.562007Z"
        },
        "trusted": true,
        "id": "CA-a9fPMLQsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:36:05.761553Z",
          "iopub.execute_input": "2024-04-29T20:36:05.762357Z",
          "iopub.status.idle": "2024-04-29T20:36:05.766382Z",
          "shell.execute_reply.started": "2024-04-29T20:36:05.762325Z",
          "shell.execute_reply": "2024-04-29T20:36:05.765439Z"
        },
        "trusted": true,
        "id": "wn3qs8nKLQsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = []\n",
        "ndcg_list = []\n",
        "hit_list = []\n",
        "for epoch in tqdm(range(1, config['num_epochs'] + 1)):\n",
        "    train_loss = train(\n",
        "        model = model,\n",
        "        criterion = criterion,\n",
        "        optimizer = optimizer,\n",
        "        data_loader = data_loader)\n",
        "    loss_list.append(train_loss)\n",
        "    print(f'Epoch: {epoch:3d}| Train loss: {train_loss:.5f}')\n",
        "\n",
        "#torch.save(model.state_dict(), os.path.join('/kaggle/working', 'checkpoint.pth'))\n",
        "torch.save(model.state_dict(), os.path.join('/content/', 'checkpoint.pth'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:36:26.202842Z",
          "iopub.execute_input": "2024-04-29T20:36:26.203644Z",
          "iopub.status.idle": "2024-04-29T20:50:26.560599Z",
          "shell.execute_reply.started": "2024-04-29T20:36:26.203613Z",
          "shell.execute_reply": "2024-04-29T20:50:26.559544Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwjFZkwxLQsk",
        "outputId": "12fd4c31-fbf9-4a28-85d7-cc622bcacdbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            " 20%|██        | 1/5 [00:10<00:40, 10.23s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:29<00:46, 15.46s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:39<00:26, 13.23s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:49<00:11, 11.64s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:56<00:00, 11.30s/it]\n",
            " 10%|█         | 1/10 [00:56<08:28, 56.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   1| Train loss: 10.41426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:11<00:44, 11.06s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:19<00:27,  9.29s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:28<00:18,  9.28s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:36<00:08,  8.93s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:43<00:00,  8.71s/it]\n",
            " 20%|██        | 2/10 [01:40<06:31, 48.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   2| Train loss: 9.57586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:10<00:42, 10.53s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:18<00:27,  9.01s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:27<00:18,  9.09s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:36<00:09,  9.08s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:42<00:00,  8.57s/it]\n",
            " 30%|███       | 3/10 [02:23<05:23, 46.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   3| Train loss: 8.88723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:10<00:41, 10.28s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:18<00:27,  9.17s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:27<00:17,  8.90s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:36<00:09,  9.04s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:42<00:00,  8.52s/it]\n",
            " 40%|████      | 4/10 [03:05<04:28, 44.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   4| Train loss: 8.37904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:10<00:41, 10.29s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:19<00:28,  9.43s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:27<00:17,  8.84s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:36<00:08,  8.93s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:42<00:00,  8.49s/it]\n",
            " 50%|█████     | 5/10 [03:48<03:39, 43.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   5| Train loss: 8.18740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:10<00:41, 10.47s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:19<00:29,  9.85s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:27<00:17,  8.97s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:36<00:08,  8.98s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:42<00:00,  8.58s/it]\n",
            " 60%|██████    | 6/10 [04:31<02:54, 43.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   6| Train loss: 8.02332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:10<00:41, 10.41s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:19<00:29,  9.82s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:27<00:18,  9.02s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:37<00:09,  9.09s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:43<00:00,  8.69s/it]\n",
            " 70%|███████   | 7/10 [05:14<02:10, 43.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   7| Train loss: 7.86853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:11<00:45, 11.41s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:20<00:30, 10.04s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:29<00:18,  9.43s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:37<00:08,  8.95s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:45<00:00,  9.00s/it]\n",
            " 80%|████████  | 8/10 [05:59<01:28, 44.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   8| Train loss: 7.79173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:09<00:36,  9.11s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:18<00:27,  9.19s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:27<00:18,  9.22s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:35<00:08,  8.62s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:42<00:00,  8.56s/it]\n",
            " 90%|█████████ | 9/10 [06:42<00:43, 43.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   9| Train loss: 7.66510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:09<00:37,  9.42s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:18<00:27,  9.07s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:27<00:18,  9.13s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:35<00:08,  8.58s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:42<00:00,  8.53s/it]\n",
            "100%|██████████| 10/10 [07:25<00:00, 44.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  10| Train loss: 7.64647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ndcg, hit = evaluate(\n",
        "    model = model,\n",
        "    user_train = user_train,\n",
        "    user_valid = user_valid,\n",
        "    max_len = config['max_len'],\n",
        "    data_loader = None,\n",
        "    make_sequence_dataset = make_sequence_dataset,\n",
        "    bert4rec_dataset = bert4rec_dataset\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:51:13.292400Z",
          "iopub.execute_input": "2024-04-29T20:51:13.292792Z",
          "iopub.status.idle": "2024-04-29T20:59:47.692526Z",
          "shell.execute_reply.started": "2024-04-29T20:51:13.292747Z",
          "shell.execute_reply": "2024-04-29T20:59:47.691594Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vLFMYl3LQsk",
        "outputId": "20fb9338-c6e4-4ac6-b82c-5979b0d90cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 610/610 [00:17<00:00, 35.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'NDCG@10: {ndcg}| HIT@10: {hit}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T21:00:31.566083Z",
          "iopub.execute_input": "2024-04-29T21:00:31.566745Z",
          "iopub.status.idle": "2024-04-29T21:00:31.571634Z",
          "shell.execute_reply.started": "2024-04-29T21:00:31.566712Z",
          "shell.execute_reply": "2024-04-29T21:00:31.570685Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGj-e5BoLQsl",
        "outputId": "728823ef-b640-41cc-f685-adb83b00c9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDCG@10: 0.3252641780558016| HIT@10: 0.5311475409836065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
        "ax = ax.flatten()\n",
        "epochs = [i for i in range(1, config['num_epochs'] + 1)]\n",
        "# Check if ndcg_list is empty\n",
        "if not ndcg_list:\n",
        "    print(\"ndcg_list is empty. Skipping plotting.\")\n",
        "else:\n",
        "    ax[1].plot(epochs, ndcg_list)\n",
        "    ax[1].set_title('NDCG')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "ax[0].plot(epochs, loss_list)\n",
        "ax[0].set_title('Loss')\n",
        "\n",
        "#ax[1].plot(epochs, ndcg_list)\n",
        "#ax[1].set_title('NDCG')\n",
        "\n",
        "#ax[2].plot(epochs, hit_list)\n",
        "#ax[2].set_title('HIT')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T21:04:35.456345Z",
          "iopub.execute_input": "2024-04-29T21:04:35.457140Z",
          "iopub.status.idle": "2024-04-29T21:04:36.056561Z",
          "shell.execute_reply.started": "2024-04-29T21:04:35.457102Z",
          "shell.execute_reply": "2024-04-29T21:04:36.055261Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "25JlZe01LQsl",
        "outputId": "a69d0fc5-f65b-4638-d8c1-d2d587eb06eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndcg_list is empty. Skipping plotting.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (10,) and (0,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-71472c6c3faa>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (0,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPM0eI6nLQsm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}