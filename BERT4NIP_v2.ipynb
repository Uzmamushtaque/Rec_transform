{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONYAxGsFdKyTqQqHqj1eS8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzmamushtaque/Rec_transform/blob/main/BERT4NIP_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1oLULCOk2gPg"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "import itertools\n",
        "# from box import Box\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'data_path' : '/content/ratings.csv',\n",
        "    'max_len' : 64,\n",
        "    'hidden_units' : 256, # Embedding size\n",
        "    'num_heads' : 2, # Multi-head layer\n",
        "    'num_layers': 2, # block (encoder layer)\n",
        "    'dropout_rate' : 0.1, # dropout\n",
        "    'lr' : 0.001,\n",
        "    'batch_size' : 32,\n",
        "    'num_epochs' : 4,\n",
        "    'num_workers' : 2,\n",
        "    'mask_prob' : 0.05, # for cloze task\n",
        "    'time_seq' : 500, # time limit for one sequence\n",
        "    'test_size' : 0.33\n",
        "\n",
        "}\n",
        "\n",
        "MAX_LEN = 100\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz-vQs2d2tVS",
        "outputId": "0bcd8bdc-e985-4753-c412-29d626be6116"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(config['data_path'])"
      ],
      "metadata": {
        "id": "nKSwPnEMHMYv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B-30cY4WHPeA",
        "outputId": "a4703584-f283-4c05-baba-b45477ccf13c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27874a68-e018-45dc-8761-428e120a9223\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27874a68-e018-45dc-8761-428e120a9223')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27874a68-e018-45dc-8761-428e120a9223 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27874a68-e018-45dc-8761-428e120a9223');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f15c1c2f-5c6b-4dae-92a4-eba52d80c6b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f15c1c2f-5c6b-4dae-92a4-eba52d80c6b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f15c1c2f-5c6b-4dae-92a4-eba52d80c6b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MakeSequenceDataSet():\n",
        "    \"\"\"\n",
        "    SequenceData\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        #self.df = pd.read_csv(os.path.join(config['data_path'], 'rating.csv'))\n",
        "        self.df = pd.read_csv(config['data_path'])\n",
        "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('movieId')\n",
        "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('userId')\n",
        "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
        "\n",
        "        self.df['item_idx'] = self.df['movieId'].apply(lambda x : self.item_encoder[x] + 1)\n",
        "        self.df['user_idx'] = self.df['userId'].apply(lambda x : self.user_encoder[x])\n",
        "        self.df = self.df.sort_values(['user_idx', 'timestamp'])\n",
        "        self.final_df = pd.DataFrame(self.get_sequence().items(),columns=['user_idx', 'items'])\n",
        "\n",
        "    def num_item(self):\n",
        "      return self.num_item\n",
        "\n",
        "    def generate_encoder_decoder(self, col : str) -> dict:\n",
        "        \"\"\"\n",
        "        encoder, decoder\n",
        "\n",
        "        Args:\n",
        "            col (str):  columns\n",
        "        Returns:\n",
        "            dict: user encoder, decoder\n",
        "        \"\"\"\n",
        "\n",
        "        encoder = {}\n",
        "        decoder = {}\n",
        "        ids = self.df[col].unique()\n",
        "\n",
        "        for idx, _id in enumerate(ids):\n",
        "            encoder[_id] = idx\n",
        "            decoder[idx] = _id\n",
        "\n",
        "        return encoder, decoder\n",
        "\n",
        "    def get_sequence(self):\n",
        "      users = defaultdict(list)\n",
        "      for user, item in zip(self.df['user_idx'], self.df['item_idx']):\n",
        "          users[user].append(item)\n",
        "      return users\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "0BseeeQIBEFT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = MakeSequenceDataSet(config)"
      ],
      "metadata": {
        "id": "jl0tjrKBByQT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#s.final_df.iloc[random.randint(0,len(s.final_df)),1]\n",
        "s.final_df.iloc[1][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEj6F4KuJ7DO",
        "outputId": "041d010c-28e0-4c68-d5d6-9a7c51fd2e31"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[233,\n",
              " 245,\n",
              " 259,\n",
              " 257,\n",
              " 252,\n",
              " 255,\n",
              " 220,\n",
              " 250,\n",
              " 243,\n",
              " 251,\n",
              " 244,\n",
              " 235,\n",
              " 236,\n",
              " 253,\n",
              " 242,\n",
              " 240,\n",
              " 237,\n",
              " 19,\n",
              " 238,\n",
              " 239,\n",
              " 254,\n",
              " 241,\n",
              " 248,\n",
              " 247,\n",
              " 249,\n",
              " 234,\n",
              " 258,\n",
              " 256,\n",
              " 246]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "  def __init__(self, data, max_len,seq_len,mask_prob) -> None:\n",
        "     super().__init__()\n",
        "     self.data = data\n",
        "     self.max_len = max_len\n",
        "     self.seq_len = seq_len\n",
        "     self.mask_prob = mask_prob\n",
        "     temp = max(self.data.item_encoder.values())\n",
        "     self.special = {'[CLS]': temp+1,\n",
        "                     '[SEP]': temp+2,\n",
        "                     '[MASK]': temp+3,\n",
        "                     '[PAD]': 0}\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data.final_df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Step 1: get random sentence pair, either negative or positive (saved as is_next_label)\n",
        "    t1, t2, is_next_label = self.get_sent(index)\n",
        "    # Step 2: replace random words in sentence with mask / random words\n",
        "    t1_random, t1_label = self.random_word(t1)\n",
        "    t2_random, t2_label = self.random_word(t2)\n",
        "    # Step 3: Adding CLS and SEP tokens to the start and end of sentences\n",
        "    # Adding PAD token for labels\n",
        "    t1 = [self.special['[CLS]']] + t1_random + [self.special['[SEP]']]\n",
        "    t2 = t2_random + [self.special['[SEP]']]\n",
        "    t1_label = [self.special['[PAD]']] + t1_label + [self.special['[PAD]']]\n",
        "    t2_label = t2_label + [self.special['[PAD]']]\n",
        "    # Step 4: combine sentence 1 and 2 as one input\n",
        "    # adding PAD tokens to make the sentence same length as seq_len\n",
        "    segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n",
        "    bert_input = (t1 + t2)[:self.seq_len]\n",
        "    bert_label = (t1_label + t2_label)[:self.seq_len]\n",
        "    padding = [self.special['[PAD]'] for _ in range(self.seq_len - len(bert_input))]\n",
        "    bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n",
        "\n",
        "    output = {\"bert_input\": bert_input,\n",
        "                  \"bert_label\": bert_label,\n",
        "                  \"segment_label\": segment_label,\n",
        "                  \"is_next\": is_next_label}\n",
        "\n",
        "    return {key: torch.tensor(value) for key, value in output.items()}\n",
        "\n",
        "\n",
        "  def random_word(self,L):\n",
        "    tokens = L\n",
        "    output_label = []\n",
        "    output = []\n",
        "    # 15% of the tokens would be replaced\n",
        "    for i, token in enumerate(tokens):\n",
        "        prob = random.random()\n",
        "\n",
        "        if prob < 0.15:\n",
        "            prob /= 0.15\n",
        "\n",
        "            # 80% chance change token to mask token\n",
        "            if prob < 0.8:\n",
        "                output.append(self.special['[MASK]'])\n",
        "\n",
        "            # 10% chance change token to random token\n",
        "            elif prob < 0.9:\n",
        "\n",
        "                output.append(random.randrange(self.data.num_item))\n",
        "\n",
        "            # 10% chance change token to current token\n",
        "            else:\n",
        "                output.append(token)\n",
        "\n",
        "            output_label.append(token)\n",
        "\n",
        "\n",
        "\n",
        "    # flattening\n",
        "    output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n",
        "    output_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output_label]))\n",
        "    assert len(output) == len(output_label)\n",
        "    return output, output_label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def get_sent(self,index):\n",
        "    t1 ,t2 = self.get_sentence_pair(self.max_len,index)\n",
        "    if random.random() > 0.5:\n",
        "      return t1,t2,1\n",
        "    else:\n",
        "      return t1,self.get_random_line()[:self.max_len],0\n",
        "\n",
        "\n",
        "\n",
        "  def get_sentence_pair(self,seq_len,index):\n",
        "    l = self.data.final_df.iloc[index][1]\n",
        "    if len(l) > seq_len:\n",
        "      return l[:seq_len], l[seq_len:2*seq_len]\n",
        "    else:\n",
        "      return l, l\n",
        "\n",
        "  def get_random_line(self):\n",
        "    return self.data.final_df.iloc[random.randint(0,len(self.data.final_df)),1]\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "bo-A0G6T11g_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t= BERTDataset(s, 10, 64,config['mask_prob'])"
      ],
      "metadata": {
        "id": "B75TvkslUC9X"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = BERTDataset(s,20, 64,config['mask_prob'] )\n",
        "train_loader = DataLoader(\n",
        "   train_data, batch_size=32, shuffle=True, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "reSZ1OduUKPL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample_data = next(iter(train_loader))\n",
        "print(train_data[random.randrange(len(train_data))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rozzkBYYGFNo",
        "outputId": "8ef0b761-e9c2-4335-d19a-4a38ff45e073"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bert_input': tensor([9724, 9726,   26, 9725, 9726, 9726, 9725,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0]), 'bert_label': tensor([   0,   17,   26,    0, 3679,   26,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0]), 'segment_label': tensor([1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'is_next': tensor(0)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s.num_item+3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmG1l4l1bY3r",
        "outputId": "dbdfd987-cb3f-4334-9f47-cb894808f138"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9727"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_len=128):\n",
        "        super().__init__()\n",
        "\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model).float()\n",
        "        pe.require_grad = False\n",
        "\n",
        "        for pos in range(max_len):\n",
        "            # for each dimension of the each position\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
        "\n",
        "        # include the batch size\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "        # self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe\n",
        "\n",
        "class BERTEmbedding(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    BERT Embedding which is consisted with under features\n",
        "        1. TokenEmbedding : normal embedding matrix\n",
        "        2. PositionalEmbedding : adding positional information using sin, cos\n",
        "        2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)\n",
        "        sum of all these features are output of BERTEmbedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, embed_size, seq_len=64, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param vocab_size: total vocab size\n",
        "        :param embed_size: embedding size of token embedding\n",
        "        :param dropout: dropout rate\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.embed_size = embed_size\n",
        "        # (m, seq_len) --> (m, seq_len, embed_size)\n",
        "        # padding_idx is not updated during training, remains as fixed pad (0)\n",
        "        self.token = torch.nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
        "        self.segment = torch.nn.Embedding(3, embed_size, padding_idx=0)\n",
        "        self.position = PositionalEmbedding(d_model=embed_size, max_len=seq_len)\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, sequence, segment_label):\n",
        "        x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "QHrFsxIJG_t9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = BERTEmbedding(s.num_item+3, 768, seq_len=64, dropout=0.1)"
      ],
      "metadata": {
        "id": "0yYdvjg4HPY5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = train_data[random.randrange(len(train_data))]"
      ],
      "metadata": {
        "id": "orrI954OHpu3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jx2OcjBaczhK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = b.forward(l['bert_input'], l['segment_label'])"
      ],
      "metadata": {
        "id": "TIIVd94vHb3c"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYENjL2SJ2jm",
        "outputId": "5c8e0c89-3aff-4bf1-b55b-71a88dd38b46"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "  def __init__(self,heads,d_model,dropout = 0.1):\n",
        "    super().__init__()\n",
        "    assert d_model % heads == 0\n",
        "    self.d_k = d_model // heads\n",
        "    self.heads = heads\n",
        "    self.dropout = torch.nn.Dropout(dropout)\n",
        "    self.query = torch.nn.Linear(d_model, d_model)\n",
        "    self.key = torch.nn.Linear(d_model, d_model)\n",
        "    self.value = torch.nn.Linear(d_model, d_model)\n",
        "    self.output_linear = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "  def forward(self, query, key, value, mask = None):\n",
        "    # (batch_size, max_len, d_model)\n",
        "    query = self.query(query.float())\n",
        "    key = self.key(key.float())\n",
        "    value = self.value(value.float())\n",
        "    # (batch_size, max_len, d_model) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n",
        "    query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
        "    key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
        "    value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
        "    # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n",
        "    scores = torch.matmul(query, key.permute(0, 1, 3, 2)) / math.sqrt(query.size(-1))\n",
        "    scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    # max_len X max_len matrix of attention\n",
        "    weights = F.softmax(scores, dim=-1)\n",
        "    weights = self.dropout(weights)\n",
        "    #print(weights.dtype)\n",
        "\n",
        "    # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n",
        "    context = torch.matmul(weights, value)\n",
        "\n",
        "    # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, d_model)\n",
        "    context = context.permute(0, 2, 1, 3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
        "\n",
        "    # (batch_size, max_len, d_model)\n",
        "    return self.output_linear(context)\n"
      ],
      "metadata": {
        "id": "S_5pDU2RIsI-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = train_data[random.randrange(len(train_data))]"
      ],
      "metadata": {
        "id": "FF6nAfSYc02k"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = MultiHeadAttention(4,768)"
      ],
      "metadata": {
        "id": "gHhICpH-c1vG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(torch.nn.Module):\n",
        "    \"Implements FFN equation.\"\n",
        "\n",
        "    def __init__(self, d_model, middle_dim=2048, dropout=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(d_model, middle_dim)\n",
        "        self.fc2 = torch.nn.Linear(middle_dim, d_model)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.activation = torch.nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.activation(self.fc1(x))\n",
        "        out = self.fc2(self.dropout(out))\n",
        "        return out\n",
        "\n",
        "class EncoderLayer(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model=768,\n",
        "        heads=12,\n",
        "        feed_forward_hidden=768 * 4,\n",
        "        dropout=0.1\n",
        "        ):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.layernorm = torch.nn.LayerNorm(d_model)\n",
        "        self.self_multihead = MultiHeadAttention(heads, d_model,dropout)\n",
        "        self.feed_forward = FeedForward(d_model, middle_dim=feed_forward_hidden)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, embeddings, mask):\n",
        "        # embeddings: (batch_size, max_len, d_model)\n",
        "        # encoder mask: (batch_size, 1, 1, max_len)\n",
        "        # result: (batch_size, max_len, d_model)\n",
        "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
        "        # residual layer\n",
        "        interacted = self.layernorm(interacted + embeddings)\n",
        "        # bottleneck\n",
        "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
        "        encoded = self.layernorm(feed_forward_out + interacted)\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "-ZFPRNkmYln7"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    BERT model : Bidirectional Encoder Representations from Transformers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, d_model=768, n_layers=12, heads=12, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param vocab_size: vocab_size of total words\n",
        "        :param hidden: BERT model hidden size\n",
        "        :param n_layers: numbers of Transformer blocks(layers)\n",
        "        :param attn_heads: number of attention heads\n",
        "        :param dropout: dropout rate\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_layers = n_layers\n",
        "        self.heads = heads\n",
        "\n",
        "        # paper noted they used 4 * hidden_size for ff_network_hidden_size\n",
        "        self.feed_forward_hidden = d_model * 4\n",
        "\n",
        "        # embedding for BERT, sum of positional, segment, token embeddings\n",
        "        self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=d_model)\n",
        "\n",
        "        # multi-layers transformer blocks, deep network\n",
        "        self.encoder_blocks = torch.nn.ModuleList(\n",
        "            [EncoderLayer(d_model, heads, d_model * 4, dropout) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, x, segment_info):\n",
        "        # attention masking for padded token\n",
        "        # (batch_size, 1, seq_len, seq_len)\n",
        "        mask = (x > 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
        "\n",
        "        # embedding the indexed sequence to sequence of vectors\n",
        "        x = self.embedding(x, segment_info)\n",
        "\n",
        "        # running over multiple transformer blocks\n",
        "        for encoder in self.encoder_blocks:\n",
        "            x = encoder.forward(x, mask)\n",
        "        return x\n",
        "\n",
        "class NextSentencePrediction(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    2-class classification model : is_next, is_not_next\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden):\n",
        "        \"\"\"\n",
        "        :param hidden: BERT model output size\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(hidden, 2)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # use only the first token which is the [CLS]\n",
        "        return self.softmax(self.linear(x[:, 0]))\n",
        "\n",
        "class MaskedLanguageModel(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    predicting origin token from masked input sequence\n",
        "    n-class classification problem, n-class = vocab_size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden, vocab_size):\n",
        "        \"\"\"\n",
        "        :param hidden: output size of BERT model\n",
        "        :param vocab_size: total vocab size\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(hidden, vocab_size)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.softmax(self.linear(x))\n",
        "\n",
        "class BERTLM(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    BERT Language Model\n",
        "    Next Sentence Prediction Model + Masked Language Model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, bert: BERT, vocab_size):\n",
        "        \"\"\"\n",
        "        :param bert: BERT model which should be trained\n",
        "        :param vocab_size: total vocab size for masked_lm\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        self.next_sentence = NextSentencePrediction(self.bert.d_model)\n",
        "        self.mask_lm = MaskedLanguageModel(self.bert.d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x, segment_label):\n",
        "        x = self.bert(x, segment_label)\n",
        "        return self.next_sentence(x), self.mask_lm(x)"
      ],
      "metadata": {
        "id": "zEY8LhBCYuki"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScheduledOptim():\n",
        "    '''A simple wrapper class for learning rate scheduling'''\n",
        "\n",
        "    def __init__(self, optimizer, d_model, n_warmup_steps):\n",
        "        self._optimizer = optimizer\n",
        "        self.n_warmup_steps = n_warmup_steps\n",
        "        self.n_current_steps = 0\n",
        "        self.init_lr = np.power(d_model, -0.5)\n",
        "\n",
        "    def step_and_update_lr(self):\n",
        "        \"Step with the inner optimizer\"\n",
        "        self._update_learning_rate()\n",
        "        self._optimizer.step()\n",
        "\n",
        "    def zero_grad(self):\n",
        "        \"Zero out the gradients by the inner optimizer\"\n",
        "        self._optimizer.zero_grad()\n",
        "\n",
        "    def _get_lr_scale(self):\n",
        "        return np.min([\n",
        "            np.power(self.n_current_steps, -0.5),\n",
        "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
        "\n",
        "    def _update_learning_rate(self):\n",
        "        ''' Learning rate scheduling per step '''\n",
        "\n",
        "        self.n_current_steps += 1\n",
        "        lr = self.init_lr * self._get_lr_scale()\n",
        "\n",
        "        for param_group in self._optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n"
      ],
      "metadata": {
        "id": "zMAOjPaTY86d"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTTrainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        train_dataloader,\n",
        "        test_dataloader=None,\n",
        "        lr= 1e-4,\n",
        "        weight_decay=0.01,\n",
        "        betas=(0.9, 0.999),\n",
        "        warmup_steps=10000,\n",
        "        log_freq=10,\n",
        "        device='cuda'\n",
        "        ):\n",
        "\n",
        "        self.device = device\n",
        "        self.model = model\n",
        "        self.train_data = train_dataloader\n",
        "        self.test_data = test_dataloader\n",
        "\n",
        "        # Setting the Adam optimizer with hyper-param\n",
        "        self.optim = Adam(self.model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
        "        self.optim_schedule = ScheduledOptim(\n",
        "            self.optim, self.model.bert.d_model, n_warmup_steps=warmup_steps\n",
        "            )\n",
        "\n",
        "        # Using Negative Log Likelihood Loss function for predicting the masked_token\n",
        "        self.criterion = torch.nn.NLLLoss(ignore_index=0)\n",
        "        self.log_freq = log_freq\n",
        "        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n",
        "\n",
        "    def train(self, epoch):\n",
        "        self.iteration(epoch, self.train_data)\n",
        "\n",
        "    def test(self, epoch):\n",
        "        self.iteration(epoch, self.test_data, train=False)\n",
        "\n",
        "    def iteration(self, epoch, data_loader, train=True):\n",
        "\n",
        "        avg_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_element = 0\n",
        "\n",
        "        mode = \"train\" if train else \"test\"\n",
        "\n",
        "        # progress bar\n",
        "        data_iter = tqdm.tqdm(\n",
        "            enumerate(data_loader),\n",
        "            desc=\"EP_%s:%d\" % (mode, epoch),\n",
        "            total=len(data_loader),\n",
        "            bar_format=\"{l_bar}{r_bar}\"\n",
        "        )\n",
        "\n",
        "        for i, data in data_iter:\n",
        "\n",
        "            # 0. batch_data will be sent into the device(GPU or cpu)\n",
        "            data = {key: value.to(self.device) for key, value in data.items()}\n",
        "            # Check if any token index is out of range\n",
        "            if (data[\"bert_input\"] >= self.model.bert.embedding.token.num_embeddings).any():\n",
        "                print(\"Error: Token indices out of range encountered.\")\n",
        "                # Further debugging, e.g., print the offending indices\n",
        "                invalid_indices = data[\"bert_input\"][data[\"bert_input\"] >= self.model.bert.embedding.token.num_embeddings]\n",
        "                print(\"Invalid indices:\", invalid_indices)\n",
        "                break  # Stop the training process\n",
        "\n",
        "            # 1. forward the next_sentence_prediction and masked_lm model\n",
        "            next_sent_output, mask_lm_output = self.model.forward(data[\"bert_input\"], data[\"segment_label\"])\n",
        "\n",
        "            # 2-1. NLL(negative log likelihood) loss of is_next classification result\n",
        "            next_loss = self.criterion(next_sent_output, data[\"is_next\"])\n",
        "\n",
        "            # 2-2. NLLLoss of predicting masked token word\n",
        "            # transpose to (m, vocab_size, seq_len) vs (m, seq_len)\n",
        "            # criterion(mask_lm_output.view(-1, mask_lm_output.size(-1)), data[\"bert_label\"].view(-1))\n",
        "            mask_loss = self.criterion(mask_lm_output.transpose(1, 2), data[\"bert_label\"])\n",
        "\n",
        "            # 2-3. Adding next_loss and mask_loss : 3.4 Pre-training Procedure\n",
        "            loss = next_loss + mask_loss\n",
        "\n",
        "            # 3. backward and optimization only in train\n",
        "            if train:\n",
        "                self.optim_schedule.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optim_schedule.step_and_update_lr()\n",
        "\n",
        "            # next sentence prediction accuracy\n",
        "            correct = next_sent_output.argmax(dim=-1).eq(data[\"is_next\"]).sum().item()\n",
        "            avg_loss += loss.item()\n",
        "            total_correct += correct\n",
        "            total_element += data[\"is_next\"].nelement()\n",
        "\n",
        "            post_fix = {\n",
        "                \"epoch\": epoch,\n",
        "                \"iter\": i,\n",
        "                \"avg_loss\": avg_loss / (i + 1),\n",
        "                \"avg_acc\": total_correct / total_element * 100,\n",
        "                \"loss\": loss.item()\n",
        "            }\n",
        "\n",
        "            if i % self.log_freq == 0:\n",
        "                data_iter.write(str(post_fix))\n",
        "        print(\n",
        "            f\"EP{epoch}, {mode}: \\\n",
        "            avg_loss={avg_loss / len(data_iter)}, \\\n",
        "            total_acc={total_correct * 100.0 / total_element}\"\n",
        "        )"
      ],
      "metadata": {
        "id": "ZXg1V4fcZCUC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''test run'''\n",
        "import tqdm\n",
        "train_data = BERTDataset(\n",
        "   s,10, 64,config['mask_prob'])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "   train_data, batch_size=32, shuffle=True, pin_memory=True)\n",
        "\n",
        "bert_model = BERT(\n",
        "  vocab_size=s.num_item+3,\n",
        "  d_model=768,\n",
        "  n_layers=2,\n",
        "  heads=12,\n",
        "  dropout=0.1\n",
        ")\n",
        "\n",
        "bert_lm = BERTLM(bert_model, s.num_item+3)\n",
        "bert_trainer = BERTTrainer(bert_lm, train_loader, device='cpu')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-clfbnfZNYe",
        "outputId": "d2c71007-e982-4836-ce94-0b1e17080b8f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 29126913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "   bert_trainer.train(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOgGBMO3a38W",
        "outputId": "7838cf73-bb12-4e83-f759-b5aebcb21f01"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:   0%|| 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EP_train:0:   5%|| 1/20 [00:07<02:31,  8.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 0, 'iter': 0, 'avg_loss': 9.793241500854492, 'avg_acc': 56.25, 'loss': 9.793241500854492}\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  10%|| 2/20 [00:13<02:00,  6.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  15%|| 3/20 [00:20<01:53,  6.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  20%|| 4/20 [00:25<01:37,  6.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  25%|| 5/20 [00:30<01:26,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  30%|| 6/20 [00:37<01:22,  5.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  35%|| 7/20 [00:42<01:13,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  40%|| 8/20 [00:48<01:10,  5.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  45%|| 9/20 [00:53<01:02,  5.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  50%|| 10/20 [00:59<00:58,  5.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EP_train:0:  55%|| 11/20 [01:05<00:51,  5.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 0, 'iter': 10, 'avg_loss': 9.78149075941606, 'avg_acc': 54.26136363636363, 'loss': 9.720915794372559}\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  60%|| 12/20 [01:10<00:44,  5.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  65%|| 13/20 [01:17<00:42,  6.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  70%|| 14/20 [01:22<00:34,  5.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  75%|| 15/20 [01:29<00:29,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  80%|| 16/20 [01:34<00:22,  5.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  85%|| 17/20 [01:40<00:17,  5.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  90%|| 18/20 [01:45<00:11,  5.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:0:  95%|| 19/20 [01:50<00:05,  5.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 12, 64, 64]) torch.Size([2, 12, 64, 64])\n",
            "torch.Size([2, 12, 64, 64]) torch.Size([2, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EP_train:0: 100%|| 20/20 [01:51<00:00,  5.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EP0, train:             avg_loss=9.749251079559325,             total_acc=52.950819672131146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:   0%|| 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EP_train:1:   5%|| 1/20 [00:06<02:00,  6.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 1, 'iter': 0, 'avg_loss': 9.565668106079102, 'avg_acc': 34.375, 'loss': 9.565668106079102}\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  10%|| 2/20 [00:11<01:42,  5.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  15%|| 3/20 [00:18<01:42,  6.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  20%|| 4/20 [00:23<01:30,  5.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  25%|| 5/20 [00:29<01:26,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  30%|| 6/20 [00:34<01:19,  5.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  35%|| 7/20 [00:39<01:11,  5.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  40%|| 8/20 [00:46<01:09,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  45%|| 9/20 [00:51<01:01,  5.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  50%|| 10/20 [00:57<00:58,  5.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EP_train:1:  55%|| 11/20 [01:02<00:50,  5.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 1, 'iter': 10, 'avg_loss': 9.643505269830877, 'avg_acc': 47.44318181818182, 'loss': 9.597225189208984}\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  60%|| 12/20 [01:08<00:44,  5.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  65%|| 13/20 [01:14<00:40,  5.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  70%|| 14/20 [01:19<00:33,  5.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  75%|| 15/20 [01:27<00:31,  6.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  80%|| 16/20 [01:32<00:23,  5.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  85%|| 17/20 [01:39<00:18,  6.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  90%|| 18/20 [01:44<00:11,  5.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n",
            "torch.Size([32, 12, 64, 64]) torch.Size([32, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEP_train:1:  95%|| 19/20 [01:50<00:05,  5.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 12, 64, 64]) torch.Size([2, 12, 64, 64])\n",
            "torch.Size([2, 12, 64, 64]) torch.Size([2, 12, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EP_train:1: 100%|| 20/20 [01:51<00:00,  5.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EP1, train:             avg_loss=9.58076901435852,             total_acc=48.19672131147541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}