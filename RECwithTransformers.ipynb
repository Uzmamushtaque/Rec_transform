{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyONd5O9hnXXYgi5BPGZBKoC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzmamushtaque/Rec_transform/blob/main/RECwithTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "from torchtext.vocab import vocab\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZKmmFnQAkpF",
        "outputId": "4b71ceb1-ec7c-47b3-f822-90764c26bfb4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading dataset\n",
        "urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-1m.zip\", \"movielens.zip\")\n",
        "ZipFile(\"movielens.zip\", \"r\").extractall()\n",
        "\n",
        "# Loading dataset\n",
        "users = pd.read_csv(\n",
        "    \"ml-1m/users.dat\",\n",
        "    sep=\"::\",\n",
        "    names=[\"user_id\", \"sex\", \"age_group\", \"occupation\", \"zip_code\"],\n",
        ")\n",
        "\n",
        "ratings = pd.read_csv(\n",
        "    \"ml-1m/ratings.dat\",\n",
        "    sep=\"::\",\n",
        "    names=[\"user_id\", \"movie_id\", \"rating\", \"unix_timestamp\"],\n",
        ")\n",
        "movies = pd.read_csv(\n",
        "    \"ml-1m/movies.dat\", sep=\"::\", names=[\"movie_id\", \"title\", \"genres\"], encoding='latin-1'\n",
        ")"
      ],
      "metadata": {
        "id": "p6otJpqPW7TP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preventing ids to be written as integer or float data type\n",
        "users[\"user_id\"] = users[\"user_id\"].apply(lambda x: f\"user_{x}\")\n",
        "movies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: f\"movie_{x}\")\n",
        "ratings[\"movie_id\"] = ratings[\"movie_id\"].apply(lambda x: f\"movie_{x}\")\n",
        "ratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: f\"user_{x}\")"
      ],
      "metadata": {
        "id": "F9dqojXEW_-C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Genarting a list of unique movie ids\n",
        "movie_ids = movies.movie_id.unique()\n",
        "\n",
        "# Counter is used to feed movies to movive_vocab\n",
        "movie_counter = Counter(movie_ids)\n",
        "\n",
        "# Genarting vocabulary\n",
        "movie_vocab = vocab(movie_counter, specials=['<unk>'])\n",
        "\n",
        "# For indexing input ids\n",
        "movie_vocab_stoi = movie_vocab.get_stoi()\n",
        "\n",
        "# Movie to title mapping dictionary\n",
        "movie_title_dict = dict(zip(movies.movie_id, movies.title))\n",
        "\n",
        "# Similarly generating a vocabulary for user ids\n",
        "user_ids = users.user_id.unique()\n",
        "user_counter = Counter(user_ids)\n",
        "user_vocab = vocab(user_counter, specials=['<unk>'])\n",
        "user_vocab_stoi = user_vocab.get_stoi()"
      ],
      "metadata": {
        "id": "dnqXdMTuXQnh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group ratings by user_id in order of increasing unix_timestamp.\n",
        "ratings_group = ratings.sort_values(by=[\"unix_timestamp\"]).groupby(\"user_id\")\n",
        "\n",
        "ratings_data = pd.DataFrame(\n",
        "    data={\n",
        "        \"user_id\": list(ratings_group.groups.keys()),\n",
        "        \"movie_ids\": list(ratings_group.movie_id.apply(list)),\n",
        "        \"timestamps\": list(ratings_group.unix_timestamp.apply(list)),\n",
        "    }\n",
        ")\n",
        "\n",
        "# Sequence length, min history count and window slide size\n",
        "sequence_length = 4\n",
        "min_history = 1\n",
        "step_size = 2\n",
        "\n",
        "# Creating sequences from lists with sliding window\n",
        "def create_sequences(values, window_size, step_size, min_history):\n",
        "  sequences = []\n",
        "  start_index = 0\n",
        "  while len(values[start_index:]) > min_history:\n",
        "    seq = values[start_index : start_index + window_size]\n",
        "    sequences.append(seq)\n",
        "    start_index += step_size\n",
        "  return sequences\n",
        "\n",
        "ratings_data.movie_ids = ratings_data.movie_ids.apply(\n",
        "    lambda ids: create_sequences(ids, sequence_length, step_size, min_history)\n",
        ")\n",
        "\n",
        "del ratings_data[\"timestamps\"]\n",
        "\n",
        "# Sub-sequences are exploded.\n",
        "# Since there might be more than one sequence for each user.\n",
        "ratings_data_transformed = ratings_data[[\"user_id\", \"movie_ids\"]].explode(\n",
        "    \"movie_ids\", ignore_index=True\n",
        ")\n",
        "\n",
        "ratings_data_transformed.rename(\n",
        "    columns={\"movie_ids\": \"sequence_movie_ids\"},\n",
        "    inplace=True,\n",
        ")"
      ],
      "metadata": {
        "id": "9E4aIpByXfY9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random indexing\n",
        "random_selection = np.random.rand(len(ratings_data_transformed.index)) <= 0.85\n",
        "\n",
        "# Split train data\n",
        "df_train_data = ratings_data_transformed[random_selection]\n",
        "train_data_raw = df_train_data[[\"user_id\", \"sequence_movie_ids\"]].values\n",
        "\n",
        "# Split test data\n",
        "df_test_data = ratings_data_transformed[~random_selection]\n",
        "test_data_raw = df_test_data[[\"user_id\", \"sequence_movie_ids\"]].values"
      ],
      "metadata": {
        "id": "qY4lSaGVXhHP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch Dataset for user interactions\n",
        "class MovieSeqDataset(Dataset):\n",
        "    # Initialize dataset\n",
        "    def __init__(self, data, movie_vocab_stoi, user_vocab_stoi):\n",
        "        self.data = data\n",
        "        self.movie_vocab_stoi = movie_vocab_stoi\n",
        "        self.user_vocab_stoi = user_vocab_stoi\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    # Fetch data from the dataset\n",
        "    def __getitem__(self, idx):\n",
        "        user, movie_sequence = self.data[idx]\n",
        "        # Directly index into the vocabularies\n",
        "        movie_data = [self.movie_vocab_stoi[item] for item in movie_sequence]\n",
        "        user_data = self.user_vocab_stoi[user]\n",
        "        return torch.tensor(movie_data), torch.tensor(user_data)\n",
        "\n",
        "\n",
        "# Collate function and padding\n",
        "def collate_batch(batch):\n",
        "    movie_list = [item[0] for item in batch]\n",
        "    user_list = [item[1] for item in batch]\n",
        "    return pad_sequence(movie_list, padding_value=movie_vocab_stoi['<unk>'], batch_first=True), torch.stack(user_list)\n",
        "\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "# Create instances of your Dataset for each set\n",
        "train_dataset = MovieSeqDataset(train_data_raw, movie_vocab_stoi, user_vocab_stoi)\n",
        "val_dataset = MovieSeqDataset(test_data_raw, movie_vocab_stoi, user_vocab_stoi)\n",
        "# Create DataLoaders\n",
        "train_iter = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=collate_batch)\n",
        "val_iter = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                      shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "4lA0kUjjXmLG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "\n",
        "        # `div_term` is used in the calculation of the sinusoidal values.\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # Initializing positional encoding matrix with zeros.\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "\n",
        "        # Calculating the positional encodings.\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "DTVQhQ-hXsiK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken: int, nuser: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        # positional encoder\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        # Multihead attention mechanism.\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "\n",
        "        # Embedding layers\n",
        "        self.movie_embedding = nn.Embedding(ntoken, d_model)\n",
        "        self.user_embedding = nn.Embedding(nuser, d_model)\n",
        "\n",
        "        # Defining the size of the input to the model.\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Linear layer to map the output tomovie vocabulary.\n",
        "        self.linear = nn.Linear(2*d_model, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        # Initializing the weights of the embedding and linear layers.\n",
        "        initrange = 0.1\n",
        "        self.movie_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.user_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.linear.bias.data.zero_()\n",
        "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: Tensor, user: Tensor, src_mask: Tensor = None) -> Tensor:\n",
        "        # Embedding movie ids and userid\n",
        "        movie_embed = self.movie_embedding(src) * math.sqrt(self.d_model)\n",
        "        user_embed = self.user_embedding(user) * math.sqrt(self.d_model)\n",
        "\n",
        "        # positional encoding\n",
        "        movie_embed = self.pos_encoder(movie_embed)\n",
        "\n",
        "        # generating output with final layers\n",
        "        output = self.transformer_encoder(movie_embed, src_mask)\n",
        "\n",
        "        # Expand user_embed tensor along the sequence length dimension\n",
        "        user_embed = user_embed.expand(-1, output.size(1), -1)\n",
        "\n",
        "        # Concatenate user embeddings with transformer output\n",
        "        output = torch.cat((output, user_embed), dim=-1)\n",
        "\n",
        "        output = self.linear(output)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "A9MnOY3oXw_7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ntokens = len(movie_vocab)  # size of vocabulary\n",
        "nusers = len(user_vocab)\n",
        "emsize = 128  # embedding dimension\n",
        "d_hid = 128  # dimension of the feedforward network model\n",
        "nlayers = 2  # number of ``nn.TransformerEncoderLayer``\n",
        "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
        "dropout = 0.2  # dropout probability\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = TransformerModel(ntokens, nusers, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 1.0  # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
      ],
      "metadata": {
        "id": "3LBNTYiZX5hG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: nn.Module, train_iter, epoch) -> None:\n",
        "    # Switch to training mode\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (movie_data, user_data) in enumerate(train_iter):\n",
        "        # Load movie sequence and user id\n",
        "        movie_data, user_data = movie_data.to(device), user_data.to(device)\n",
        "        user_data = user_data.reshape(-1, 1)\n",
        "\n",
        "        # Split movie sequence to inputs and targets\n",
        "        inputs, targets = movie_data[:, :-1], movie_data[:, 1:]\n",
        "        targets_flat = targets.reshape(-1)\n",
        "\n",
        "        # Predict movies\n",
        "        output = model(inputs, user_data)\n",
        "        output_flat = output.reshape(-1, ntokens)\n",
        "\n",
        "        # Backpropogation process\n",
        "        loss = criterion(output_flat, targets_flat)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Results\n",
        "        if i % log_interval == 0 and i > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()"
      ],
      "metadata": {
        "id": "vKtp82wqX9lz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    # Switch the model to evaluation mode.\n",
        "    # This is necessary for layers like dropout,\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (movie_data, user_data) in enumerate(eval_data):\n",
        "            # Load movie sequence and user id\n",
        "            movie_data, user_data = movie_data.to(device), user_data.to(device)\n",
        "            user_data = user_data.reshape(-1, 1)\n",
        "            # Split movie sequence to inputs and targets\n",
        "            inputs, targets = movie_data[:, :-1], movie_data[:, 1:]\n",
        "            targets_flat = targets.reshape(-1)\n",
        "            # Predict movies\n",
        "            output = model(inputs, user_data)\n",
        "            output_flat = output.reshape(-1, ntokens)\n",
        "            # Calculate loss\n",
        "            loss = criterion(output_flat, targets_flat)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / (len(eval_data) - 1)\n"
      ],
      "metadata": {
        "id": "u2YuSkMJYBK-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = 10\n",
        "\n",
        "with TemporaryDirectory() as tempdir:\n",
        "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        # Training\n",
        "        train(model,train_iter,epoch)\n",
        "\n",
        "        # Evaluation\n",
        "        val_loss = evaluate(model, val_iter)\n",
        "\n",
        "        # Compute the perplexity of the validation loss\n",
        "        val_ppl = math.exp(val_loss)\n",
        "        elapsed = time.time() - epoch_start_time\n",
        "\n",
        "        # Results\n",
        "        print('-' * 89)\n",
        "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "        print('-' * 89)\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        scheduler.step()\n",
        "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bjdBGneYHa4",
        "outputId": "585202c5-4aaa-4e90-e281-f7c35dfa26b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 lr 1.00 | ms/batch 34.50 | loss  7.79 | ppl  2418.15\n",
            "| epoch   1 lr 1.00 | ms/batch 18.62 | loss  7.62 | ppl  2032.40\n",
            "| epoch   1 lr 1.00 | ms/batch 17.49 | loss  7.59 | ppl  1970.60\n",
            "| epoch   1 lr 1.00 | ms/batch 16.38 | loss  7.55 | ppl  1909.10\n",
            "| epoch   1 lr 1.00 | ms/batch 16.20 | loss  7.53 | ppl  1862.52\n",
            "| epoch   1 lr 1.00 | ms/batch 15.60 | loss  7.45 | ppl  1717.11\n",
            "| epoch   1 lr 1.00 | ms/batch 13.43 | loss  7.29 | ppl  1468.84\n",
            "| epoch   1 lr 1.00 | ms/batch 12.22 | loss  7.11 | ppl  1226.79\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 31.42s | valid loss  6.98 | valid ppl  1074.70\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 lr 0.95 | ms/batch 13.41 | loss  6.89 | ppl   983.00\n",
            "| epoch   2 lr 0.95 | ms/batch 11.99 | loss  6.78 | ppl   880.94\n",
            "| epoch   2 lr 0.95 | ms/batch 10.32 | loss  6.72 | ppl   825.26\n",
            "| epoch   2 lr 0.95 | ms/batch 10.39 | loss  6.66 | ppl   777.94\n",
            "| epoch   2 lr 0.95 | ms/batch 10.25 | loss  6.61 | ppl   740.89\n",
            "| epoch   2 lr 0.95 | ms/batch 10.24 | loss  6.57 | ppl   713.51\n",
            "| epoch   2 lr 0.95 | ms/batch 14.36 | loss  6.52 | ppl   680.84\n",
            "| epoch   2 lr 0.95 | ms/batch 10.12 | loss  6.49 | ppl   660.35\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 20.67s | valid loss  6.52 | valid ppl   676.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 lr 0.90 | ms/batch 10.65 | loss  6.39 | ppl   597.41\n",
            "| epoch   3 lr 0.90 | ms/batch 10.31 | loss  6.34 | ppl   568.38\n",
            "| epoch   3 lr 0.90 | ms/batch 12.89 | loss  6.33 | ppl   558.46\n",
            "| epoch   3 lr 0.90 | ms/batch 11.96 | loss  6.31 | ppl   551.68\n",
            "| epoch   3 lr 0.90 | ms/batch 10.23 | loss  6.30 | ppl   545.85\n",
            "| epoch   3 lr 0.90 | ms/batch 10.28 | loss  6.29 | ppl   541.16\n",
            "| epoch   3 lr 0.90 | ms/batch 10.23 | loss  6.28 | ppl   532.19\n",
            "| epoch   3 lr 0.90 | ms/batch 11.66 | loss  6.27 | ppl   526.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 21.70s | valid loss  6.37 | valid ppl   583.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 lr 0.86 | ms/batch 10.93 | loss  6.17 | ppl   480.52\n",
            "| epoch   4 lr 0.86 | ms/batch 12.22 | loss  6.14 | ppl   461.96\n",
            "| epoch   4 lr 0.86 | ms/batch 10.27 | loss  6.13 | ppl   458.37\n",
            "| epoch   4 lr 0.86 | ms/batch 10.23 | loss  6.14 | ppl   465.14\n",
            "| epoch   4 lr 0.86 | ms/batch 14.21 | loss  6.13 | ppl   461.01\n",
            "| epoch   4 lr 0.86 | ms/batch 10.34 | loss  6.13 | ppl   458.69\n",
            "| epoch   4 lr 0.86 | ms/batch 10.50 | loss  6.13 | ppl   460.83\n",
            "| epoch   4 lr 0.86 | ms/batch 10.19 | loss  6.12 | ppl   454.71\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 20.25s | valid loss  6.30 | valid ppl   544.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 lr 0.81 | ms/batch 13.15 | loss  6.03 | ppl   415.77\n",
            "| epoch   5 lr 0.81 | ms/batch 11.87 | loss  6.00 | ppl   403.40\n",
            "| epoch   5 lr 0.81 | ms/batch 10.18 | loss  6.01 | ppl   408.66\n",
            "| epoch   5 lr 0.81 | ms/batch 10.12 | loss  6.01 | ppl   408.78\n",
            "| epoch   5 lr 0.81 | ms/batch 10.25 | loss  6.02 | ppl   409.58\n",
            "| epoch   5 lr 0.81 | ms/batch 10.10 | loss  6.01 | ppl   406.24\n",
            "| epoch   5 lr 0.81 | ms/batch 14.27 | loss  6.02 | ppl   410.12\n",
            "| epoch   5 lr 0.81 | ms/batch 10.36 | loss  6.01 | ppl   407.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 20.52s | valid loss  6.26 | valid ppl   523.92\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 lr 0.77 | ms/batch 10.56 | loss  5.91 | ppl   370.51\n",
            "| epoch   6 lr 0.77 | ms/batch 10.02 | loss  5.90 | ppl   366.04\n",
            "| epoch   6 lr 0.77 | ms/batch 12.06 | loss  5.91 | ppl   369.66\n",
            "| epoch   6 lr 0.77 | ms/batch 12.99 | loss  5.92 | ppl   371.92\n",
            "| epoch   6 lr 0.77 | ms/batch 10.28 | loss  5.91 | ppl   368.33\n",
            "| epoch   6 lr 0.77 | ms/batch 10.14 | loss  5.93 | ppl   375.73\n",
            "| epoch   6 lr 0.77 | ms/batch 10.11 | loss  5.92 | ppl   373.54\n",
            "| epoch   6 lr 0.77 | ms/batch 10.23 | loss  5.93 | ppl   374.61\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 20.58s | valid loss  6.24 | valid ppl   513.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 lr 0.74 | ms/batch 10.60 | loss  5.83 | ppl   341.18\n",
            "| epoch   7 lr 0.74 | ms/batch 10.11 | loss  5.81 | ppl   333.73\n",
            "| epoch   7 lr 0.74 | ms/batch 10.11 | loss  5.82 | ppl   337.16\n",
            "| epoch   7 lr 0.74 | ms/batch 10.25 | loss  5.84 | ppl   343.18\n",
            "| epoch   7 lr 0.74 | ms/batch 11.14 | loss  5.85 | ppl   346.86\n",
            "| epoch   7 lr 0.74 | ms/batch 13.89 | loss  5.84 | ppl   344.55\n",
            "| epoch   7 lr 0.74 | ms/batch 10.37 | loss  5.86 | ppl   349.65\n",
            "| epoch   7 lr 0.74 | ms/batch 10.43 | loss  5.86 | ppl   350.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 19.85s | valid loss  6.23 | valid ppl   507.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 lr 0.70 | ms/batch 10.74 | loss  5.76 | ppl   316.40\n",
            "| epoch   8 lr 0.70 | ms/batch 13.63 | loss  5.75 | ppl   312.98\n",
            "| epoch   8 lr 0.70 | ms/batch 10.78 | loss  5.75 | ppl   313.60\n",
            "| epoch   8 lr 0.70 | ms/batch  9.98 | loss  5.78 | ppl   322.65\n",
            "| epoch   8 lr 0.70 | ms/batch 10.03 | loss  5.78 | ppl   323.77\n",
            "| epoch   8 lr 0.70 | ms/batch 10.21 | loss  5.78 | ppl   324.28\n",
            "| epoch   8 lr 0.70 | ms/batch 10.15 | loss  5.80 | ppl   328.72\n",
            "| epoch   8 lr 0.70 | ms/batch 14.21 | loss  5.79 | ppl   328.47\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 20.37s | valid loss  6.22 | valid ppl   503.82\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 lr 0.66 | ms/batch 10.82 | loss  5.69 | ppl   296.88\n",
            "| epoch   9 lr 0.66 | ms/batch 10.23 | loss  5.69 | ppl   295.24\n",
            "| epoch   9 lr 0.66 | ms/batch 10.68 | loss  5.71 | ppl   301.93\n",
            "| epoch   9 lr 0.66 | ms/batch 13.07 | loss  5.71 | ppl   303.37\n",
            "| epoch   9 lr 0.66 | ms/batch 11.81 | loss  5.72 | ppl   305.38\n",
            "| epoch   9 lr 0.66 | ms/batch 10.09 | loss  5.72 | ppl   305.15\n",
            "| epoch   9 lr 0.66 | ms/batch 10.30 | loss  5.74 | ppl   310.86\n",
            "| epoch   9 lr 0.66 | ms/batch 10.32 | loss  5.74 | ppl   310.62\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 20.02s | valid loss  6.22 | valid ppl   501.77\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 lr 0.63 | ms/batch 14.09 | loss  5.65 | ppl   285.01\n",
            "| epoch  10 lr 0.63 | ms/batch 10.26 | loss  5.63 | ppl   277.94\n",
            "| epoch  10 lr 0.63 | ms/batch 10.25 | loss  5.65 | ppl   283.80\n",
            "| epoch  10 lr 0.63 | ms/batch 15.96 | loss  5.66 | ppl   287.20\n",
            "| epoch  10 lr 0.63 | ms/batch 18.41 | loss  5.67 | ppl   290.44\n",
            "| epoch  10 lr 0.63 | ms/batch 12.50 | loss  5.68 | ppl   292.59\n",
            "| epoch  10 lr 0.63 | ms/batch 10.20 | loss  5.70 | ppl   299.04\n",
            "| epoch  10 lr 0.63 | ms/batch 10.16 | loss  5.71 | ppl   300.41\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 22.88s | valid loss  6.22 | valid ppl   501.15\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_popular_movies(df_ratings):\n",
        "  # Calculate the number of ratings for each movie\n",
        "  rating_counts = df_ratings['movie_id'].value_counts().reset_index()\n",
        "  rating_counts.columns = ['movie_id', 'rating_count']\n",
        "\n",
        "  # Get the most frequently rated movies\n",
        "  min_ratings_threshold = rating_counts['rating_count'].quantile(0.95)\n",
        "\n",
        "  # Filter movies based on the minimum number of ratings\n",
        "  popular_movies = ratings.merge(rating_counts, on='movie_id')\n",
        "  popular_movies = popular_movies[popular_movies['rating_count'] >= min_ratings_threshold]\n",
        "\n",
        "  # Calculate the average rating for each movie\n",
        "  average_ratings = popular_movies.groupby('movie_id')['rating'].mean().reset_index()\n",
        "\n",
        "  # Get the top 10 rated movies\n",
        "  top_10_movies = list(average_ratings.sort_values('rating', ascending=False).head(10).movie_id.values)\n",
        "  return top_10_movies"
      ],
      "metadata": {
        "id": "lvTSVs0jbgKu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_movies=get_popular_movies(ratings)"
      ],
      "metadata": {
        "id": "7IHjuOE8cEHu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Movie id decoder\n",
        "movie_vocab_itos = movie_vocab.get_itos()\n",
        "\n",
        "# A placeholders to store results of recommendations\n",
        "transformer_reco_results = list()\n",
        "popular_reco_results = list()\n",
        "\n",
        "# Get top 10 movies\n",
        "k = 10\n",
        "# Iterate over the validation data\n",
        "for i, (movie_data, user_data) in enumerate(val_iter):\n",
        "    # Feed the input and get the outputs\n",
        "    movie_data, user_data = movie_data.to(device), user_data.to(device)\n",
        "    user_data = user_data.reshape(-1, 1)\n",
        "    inputs, targets = movie_data[:, :-1], movie_data[:, 1:]\n",
        "    output = model(inputs, user_data)\n",
        "    output_flat = output.reshape(-1, ntokens)\n",
        "    targets_flat = targets.reshape(-1)\n",
        "\n",
        "    # Reshape the output_flat to get top predictions\n",
        "    outputs = output_flat.reshape(output_flat.shape[0] // inputs.shape[1],\n",
        "                                  inputs.shape[1],\n",
        "                                  output_flat.shape[1])[: , -1, :]\n",
        "    # k + inputs.shape[1] = 13 movies obtained\n",
        "    # In order to prevent to recommend already watched movies\n",
        "    values, indices = outputs.topk(k + inputs.shape[1], dim=-1)\n",
        "\n",
        "    for sub_sequence, sub_indice_org in zip(movie_data, indices):\n",
        "        sub_indice_org = sub_indice_org.cpu().detach().numpy()\n",
        "        sub_sequence = sub_sequence.cpu().detach().numpy()\n",
        "\n",
        "        # Generate mask array to eliminate already watched movies\n",
        "        mask = np.isin(sub_indice_org, sub_sequence[:-1], invert=True)\n",
        "\n",
        "        # After masking get top k movies\n",
        "        sub_indice = sub_indice_org[mask][:k]\n",
        "\n",
        "        # Generate results array\n",
        "        transformer_reco_result = np.isin(sub_indice, sub_sequence[-1]).astype(int)\n",
        "\n",
        "        # Decode movie to search in popular movies\n",
        "        target_movie_decoded = movie_vocab_itos[sub_sequence[-1]]\n",
        "\n",
        "        popular_reco_result = np.isin(top_10_movies, target_movie_decoded).astype(int)\n",
        "\n",
        "        transformer_reco_results.append(transformer_reco_result)\n",
        "        popular_reco_results.append(popular_reco_result)"
      ],
      "metadata": {
        "id": "tHh--mCobhN6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "# Since we have already sorted our recommendations\n",
        "# An array that represent our recommendation scores is used.\n",
        "representative_array = [[i for i in range(k, 0, -1)]] * len(transformer_reco_results)\n",
        "\n",
        "for k in [3, 5, 10]:\n",
        "  transformer_result = ndcg_score(transformer_reco_results,\n",
        "                                  representative_array, k=k)\n",
        "  popular_result = ndcg_score(popular_reco_results,\n",
        "                              representative_array, k=k)\n",
        "\n",
        "  print(f\"Transformer NDCG result at top {k}: {round(transformer_result, 4)}\")\n",
        "  print(f\"Popular recommendation NDCG result at top {k}: {round(popular_result, 4)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCHHKS1tblWo",
        "outputId": "3defe01a-547f-44e5-cbbe-d23e57be27b0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer NDCG result at top 3: 0.0528\n",
            "Popular recommendation NDCG result at top 3: 0.0043\n",
            "\n",
            "\n",
            "Transformer NDCG result at top 5: 0.0672\n",
            "Popular recommendation NDCG result at top 5: 0.0062\n",
            "\n",
            "\n",
            "Transformer NDCG result at top 10: 0.0893\n",
            "Popular recommendation NDCG result at top 10: 0.0093\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}